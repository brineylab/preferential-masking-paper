{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085ce86c-5c1e-4edb-9820-97d04c7df007",
   "metadata": {},
   "source": [
    "# Pair Classifier Inference\n",
    "\n",
    "for pair classifier models on dataset C (for use analyzing prediction performance when separated by chain pairing type - Fig. 4D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd187f-cda0-424d-a7b1-5c791ca5ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    EsmTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    Sequence,\n",
    "    Value,\n",
    "    ClassLabel,\n",
    "    load_dataset,\n",
    ")\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd5c91-263e-4781-9b57-dcadb602a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0602ae-3056-4c4b-8087-e65dfe7f680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models and corresponding test data\n",
    "pair_dict = {\n",
    "    n: {\n",
    "        # replace with actual paths to models\n",
    "        \"models\": {\n",
    "            \"uniform_250k\": f\"../models/uniform-250k_itr{n}_50ep_pairs-C\",\n",
    "            \"uniform_350k\": f\"../models/uniform-350k_itr{n}_50ep_pairs-C\",\n",
    "            \"preferential_250k\": f\"../models/preferential-250k_itr{n}_50ep_pairs-C\",\n",
    "        },\n",
    "        \"data\": f'./train-test_splits/C_native-0_shuffled-1_test{n}.csv',\n",
    "    }\n",
    "for n in range(5)}\n",
    "\n",
    "pair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2d704-1426-4dc4-b5f5-5e0062d3ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on entire test set for all 3 models\n",
    "for i in tqdm(pair_dict.keys()):\n",
    "\n",
    "    # load test data\n",
    "    test_data = pd.read_csv(pair_dict[i][\"data\"])\n",
    "    test_preds = test_data.copy() # for storing prediction metrics\n",
    "    \n",
    "    class_labels = ClassLabel(names=[\"native-pair\", \"shuffled-pair\"])\n",
    "    n_classes = len(class_labels.names)\n",
    "    label2id = {\"native-pair\": 0, \"shuffled-pair\": 1}\n",
    "    id2label = {0: \"native-pair\", 1: \"shuffled-pair\"}\n",
    "    \n",
    "    # make huggingface dataset\n",
    "    dataset = datasets.Dataset.from_pandas(test_data)\n",
    "    dataset = dataset.cast_column(\"label\", class_labels)\n",
    "    \n",
    "    # filter for length (model has max length of 320 from training)\n",
    "    def filter_long_sequences(item):\n",
    "        return (len(item['h_sequence'])+len(item['l_sequence'])) <= 315 # allows 4 tokens (start, sep (which is 2 tokens long), end)\n",
    "    filtered = dataset.filter(filter_long_sequences)\n",
    "    \n",
    "    # tokenizer\n",
    "    tokenizer = EsmTokenizer.from_pretrained(\"../tokenizer/vocab.txt\")\n",
    "    \n",
    "    def preprocess_dataset(\n",
    "        batch, \n",
    "        tokenizer=None, \n",
    "        tokenizer_path=\"./tokenizer\", \n",
    "        separator=\"<cls><cls>\",\n",
    "        max_len=320\n",
    "    ) -> list:\n",
    "        \"\"\"\n",
    "        docstring\n",
    "        \"\"\"\n",
    "        # tokenize the H/L sequence pair\n",
    "        sequences = [h + separator + l for h, l in zip(batch[\"h_sequence\"], batch[\"l_sequence\"])]\n",
    "        tokenized = tokenizer(sequences, padding=\"max_length\", max_length=max_len)\n",
    "        batch[\"input_ids\"] = tokenized.input_ids\n",
    "        batch[\"attention_mask\"] = tokenized.attention_mask\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    # tokenize\n",
    "    tokenized_dataset = filtered.map(\n",
    "        preprocess_dataset,\n",
    "        fn_kwargs={\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"max_len\": 320,\n",
    "        },\n",
    "        batched=True,\n",
    "        remove_columns=[\"name\", \"h_sequence\", \"l_sequence\", \"donor\"]\n",
    "    )\n",
    "\n",
    "    # load each model\n",
    "    for model_id, model_path in pair_dict[i][\"models\"].items():\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "    \n",
    "        # predict on test set and get metrics\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            args=TrainingArguments(output_dir=\"./\", \n",
    "                                   report_to=\"none\"), # to turn off wandb logging\n",
    "            eval_dataset=tokenized_dataset,\n",
    "        )\n",
    "        logits, labels, metrics = trainer.predict(tokenized_dataset)\n",
    "        probabilities = torch.softmax(torch.from_numpy(logits), dim=1).detach().numpy()[:, -1]\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "        \n",
    "        del model # free up memory\n",
    "        \n",
    "        # categorize predictions\n",
    "        pred_data = []\n",
    "        for pred, prob, label, logit in zip(predictions, probabilities, labels, logits):\n",
    "            if pred == label == 1:\n",
    "                category = \"true_positive\"\n",
    "            elif pred == label == 0:\n",
    "                category = \"true_negative\"\n",
    "            elif pred == 1 and label == 0:\n",
    "                category = \"false_positive\"\n",
    "            else:\n",
    "                category = \"false_negative\"\n",
    "            pred_data.append(\n",
    "                {\n",
    "                    # \"label\": label,\n",
    "                    f\"{model_id}_prediction\": pred,\n",
    "                    f\"{model_id}_probability\": prob,\n",
    "                    f\"{model_id}_category\": category,\n",
    "                    f\"{model_id}_logits\": logit,\n",
    "                }\n",
    "            )\n",
    "        pred_df = pd.DataFrame(pred_data)\n",
    "        # pred_df[\"is_correct\"] = pred_df[\"prediction\"] == pred_df[\"label\"]\n",
    "        \n",
    "        # store predictive performance with its corresponding sequence\n",
    "        test_preds = pd.concat([test_preds, pred_df], axis=1)\n",
    "    \n",
    "    # save as csv\n",
    "    test_preds.to_csv(f\"./results/data-C_predictions_itr{i}.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e5978-292a-4588-8526-d09dabcc7d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d2e68-36b7-4357-9a10-fe3d97c940ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
